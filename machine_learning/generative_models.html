<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Generative Models - My Notes</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "../searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">My Notes</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="generative-models"><a class="header" href="#generative-models">Generative Models</a></h1>
<p>Generative models learn to create new data samples that resemble the training data distribution.</p>
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<ol>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#generative-adversarial-networks">Generative Adversarial Networks (GANs)</a></li>
<li><a href="#variational-autoencoders">Variational Autoencoders (VAEs)</a></li>
<li><a href="#normalizing-flows">Normalizing Flows</a></li>
<li><a href="#autoregressive-models">Autoregressive Models</a></li>
<li><a href="#energy-based-models">Energy-Based Models</a></li>
<li><a href="#diffusion-models">Diffusion Models</a></li>
</ol>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p><strong>Types of Generative Models:</strong></p>
<ul>
<li><strong>Explicit Density</strong>: Models that define explicit probability distribution (VAE, Flow models)</li>
<li><strong>Implicit Density</strong>: Models that can sample without explicit density (GANs)</li>
<li><strong>Tractable</strong>: Can compute exact likelihoods (Autoregressive, Flow models)</li>
<li><strong>Approximate</strong>: Use approximate inference (VAEs)</li>
</ul>
<h2 id="generative-adversarial-networks"><a class="header" href="#generative-adversarial-networks">Generative Adversarial Networks</a></h2>
<p>GANs use two networks competing against each other: Generator and Discriminator.</p>
<h3 id="basic-gan"><a class="header" href="#basic-gan">Basic GAN</a></h3>
<p><strong>Objective Function:</strong></p>
<pre><code>min_G max_D V(D,G) = E_x[log D(x)] + E_z[log(1 - D(G(z)))]
</code></pre>
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

# Generator Network
class Generator(nn.Module):
    def __init__(self, latent_dim=100, img_shape=(1, 28, 28)):
        super(Generator, self).__init__()
        self.img_shape = img_shape
        
        def block(in_feat, out_feat, normalize=True):
            layers = [nn.Linear(in_feat, out_feat)]
            if normalize:
                layers.append(nn.BatchNorm1d(out_feat))
            layers.append(nn.LeakyReLU(0.2))
            return layers
        
        self.model = nn.Sequential(
            *block(latent_dim, 128, normalize=False),
            *block(128, 256),
            *block(256, 512),
            *block(512, 1024),
            nn.Linear(1024, int(np.prod(img_shape))),
            nn.Tanh()
        )
    
    def forward(self, z):
        img = self.model(z)
        img = img.view(img.size(0), *self.img_shape)
        return img

# Discriminator Network
class Discriminator(nn.Module):
    def __init__(self, img_shape=(1, 28, 28)):
        super(Discriminator, self).__init__()
        
        self.model = nn.Sequential(
            nn.Linear(int(np.prod(img_shape)), 512),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )
    
    def forward(self, img):
        img_flat = img.view(img.size(0), -1)
        validity = self.model(img_flat)
        return validity

# Training GAN
class GANTrainer:
    def __init__(self, generator, discriminator, latent_dim=100, 
                 lr=0.0002, betas=(0.5, 0.999)):
        self.generator = generator
        self.discriminator = discriminator
        self.latent_dim = latent_dim
        
        # Optimizers
        self.optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=betas)
        self.optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=betas)
        
        # Loss function
        self.adversarial_loss = nn.BCELoss()
    
    def train_step(self, real_imgs):
        batch_size = real_imgs.size(0)
        
        # Adversarial ground truths
        valid = torch.ones(batch_size, 1)
        fake = torch.zeros(batch_size, 1)
        
        # ---------------------
        #  Train Discriminator
        # ---------------------
        self.optimizer_D.zero_grad()
        
        # Loss for real images
        real_loss = self.adversarial_loss(self.discriminator(real_imgs), valid)
        
        # Loss for fake images
        z = torch.randn(batch_size, self.latent_dim)
        fake_imgs = self.generator(z)
        fake_loss = self.adversarial_loss(self.discriminator(fake_imgs.detach()), fake)
        
        # Total discriminator loss
        d_loss = (real_loss + fake_loss) / 2
        d_loss.backward()
        self.optimizer_D.step()
        
        # -----------------
        #  Train Generator
        # -----------------
        self.optimizer_G.zero_grad()
        
        # Generate fake images
        z = torch.randn(batch_size, self.latent_dim)
        gen_imgs = self.generator(z)
        
        # Generator loss (fool discriminator)
        g_loss = self.adversarial_loss(self.discriminator(gen_imgs), valid)
        g_loss.backward()
        self.optimizer_G.step()
        
        return d_loss.item(), g_loss.item()
    
    def train(self, dataloader, num_epochs=100):
        """Train GAN"""
        for epoch in range(num_epochs):
            for i, (imgs, _) in enumerate(dataloader):
                d_loss, g_loss = self.train_step(imgs)
                
                if i % 100 == 0:
                    print(f"[Epoch {epoch}/{num_epochs}] [Batch {i}] "
                          f"[D loss: {d_loss:.4f}] [G loss: {g_loss:.4f}]")
            
            # Sample images
            if epoch % 10 == 0:
                self.sample_images(epoch)
    
    def sample_images(self, epoch, n_row=10):
        """Generate and save sample images"""
        z = torch.randn(n_row**2, self.latent_dim)
        gen_imgs = self.generator(z)
        
        import torchvision.utils as vutils
        vutils.save_image(gen_imgs.data, f"images/epoch_{epoch}.png", 
                         nrow=n_row, normalize=True)

# Example usage
img_shape = (1, 28, 28)
generator = Generator(latent_dim=100, img_shape=img_shape)
discriminator = Discriminator(img_shape=img_shape)

trainer = GANTrainer(generator, discriminator)
# trainer.train(dataloader, num_epochs=100)
</code></pre>
<h3 id="deep-convolutional-gan-dcgan"><a class="header" href="#deep-convolutional-gan-dcgan">Deep Convolutional GAN (DCGAN)</a></h3>
<pre><code class="language-python">class DCGANGenerator(nn.Module):
    def __init__(self, latent_dim=100, channels=3):
        super(DCGANGenerator, self).__init__()
        
        self.init_size = 4
        self.l1 = nn.Linear(latent_dim, 128 * self.init_size ** 2)
        
        self.conv_blocks = nn.Sequential(
            nn.BatchNorm2d(128),
            nn.Upsample(scale_factor=2),  # 4x4 -&gt; 8x8
            nn.Conv2d(128, 128, 3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2),
            
            nn.Upsample(scale_factor=2),  # 8x8 -&gt; 16x16
            nn.Conv2d(128, 64, 3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2),
            
            nn.Upsample(scale_factor=2),  # 16x16 -&gt; 32x32
            nn.Conv2d(64, channels, 3, stride=1, padding=1),
            nn.Tanh()
        )
    
    def forward(self, z):
        out = self.l1(z)
        out = out.view(out.shape[0], 128, self.init_size, self.init_size)
        img = self.conv_blocks(out)
        return img

class DCGANDiscriminator(nn.Module):
    def __init__(self, channels=3):
        super(DCGANDiscriminator, self).__init__()
        
        def discriminator_block(in_filters, out_filters, bn=True):
            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1),
                    nn.LeakyReLU(0.2),
                    nn.Dropout2d(0.25)]
            if bn:
                block.append(nn.BatchNorm2d(out_filters))
            return block
        
        self.model = nn.Sequential(
            *discriminator_block(channels, 16, bn=False),  # 32x32 -&gt; 16x16
            *discriminator_block(16, 32),                   # 16x16 -&gt; 8x8
            *discriminator_block(32, 64),                   # 8x8 -&gt; 4x4
            *discriminator_block(64, 128),                  # 4x4 -&gt; 2x2
        )
        
        # Output layer
        ds_size = 2
        self.adv_layer = nn.Sequential(
            nn.Linear(128 * ds_size ** 2, 1),
            nn.Sigmoid()
        )
    
    def forward(self, img):
        out = self.model(img)
        out = out.view(out.shape[0], -1)
        validity = self.adv_layer(out)
        return validity
</code></pre>
<h3 id="conditional-gan-cgan"><a class="header" href="#conditional-gan-cgan">Conditional GAN (cGAN)</a></h3>
<pre><code class="language-python">class ConditionalGenerator(nn.Module):
    def __init__(self, latent_dim=100, n_classes=10, img_shape=(1, 28, 28)):
        super(ConditionalGenerator, self).__init__()
        self.img_shape = img_shape
        
        self.label_emb = nn.Embedding(n_classes, n_classes)
        
        def block(in_feat, out_feat, normalize=True):
            layers = [nn.Linear(in_feat, out_feat)]
            if normalize:
                layers.append(nn.BatchNorm1d(out_feat))
            layers.append(nn.LeakyReLU(0.2))
            return layers
        
        self.model = nn.Sequential(
            *block(latent_dim + n_classes, 128, normalize=False),
            *block(128, 256),
            *block(256, 512),
            *block(512, 1024),
            nn.Linear(1024, int(np.prod(img_shape))),
            nn.Tanh()
        )
    
    def forward(self, noise, labels):
        # Concatenate label embedding and noise
        gen_input = torch.cat((self.label_emb(labels), noise), -1)
        img = self.model(gen_input)
        img = img.view(img.size(0), *self.img_shape)
        return img

class ConditionalDiscriminator(nn.Module):
    def __init__(self, n_classes=10, img_shape=(1, 28, 28)):
        super(ConditionalDiscriminator, self).__init__()
        
        self.label_embedding = nn.Embedding(n_classes, n_classes)
        
        self.model = nn.Sequential(
            nn.Linear(n_classes + int(np.prod(img_shape)), 512),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )
    
    def forward(self, img, labels):
        # Concatenate label embedding and image
        d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)
        validity = self.model(d_in)
        return validity
</code></pre>
<h3 id="wasserstein-gan-wgan"><a class="header" href="#wasserstein-gan-wgan">Wasserstein GAN (WGAN)</a></h3>
<pre><code class="language-python">class WGANTrainer:
    def __init__(self, generator, discriminator, latent_dim=100, 
                 lr=0.00005, n_critic=5, clip_value=0.01):
        self.generator = generator
        self.discriminator = discriminator
        self.latent_dim = latent_dim
        self.n_critic = n_critic
        self.clip_value = clip_value
        
        # RMSprop optimizers
        self.optimizer_G = optim.RMSprop(generator.parameters(), lr=lr)
        self.optimizer_D = optim.RMSprop(discriminator.parameters(), lr=lr)
    
    def train_step(self, real_imgs):
        batch_size = real_imgs.size(0)
        
        # ---------------------
        #  Train Discriminator
        # ---------------------
        self.optimizer_D.zero_grad()
        
        # Sample noise
        z = torch.randn(batch_size, self.latent_dim)
        fake_imgs = self.generator(z).detach()
        
        # Wasserstein loss
        loss_D = -torch.mean(self.discriminator(real_imgs)) + \
                  torch.mean(self.discriminator(fake_imgs))
        
        loss_D.backward()
        self.optimizer_D.step()
        
        # Clip weights
        for p in self.discriminator.parameters():
            p.data.clamp_(-self.clip_value, self.clip_value)
        
        # Train generator every n_critic iterations
        if self.n_critic &gt; 0:
            self.n_critic -= 1
            return loss_D.item(), None
        
        # -----------------
        #  Train Generator
        # -----------------
        self.optimizer_G.zero_grad()
        
        z = torch.randn(batch_size, self.latent_dim)
        gen_imgs = self.generator(z)
        
        # Generator loss
        loss_G = -torch.mean(self.discriminator(gen_imgs))
        
        loss_G.backward()
        self.optimizer_G.step()
        
        self.n_critic = 5  # Reset
        
        return loss_D.item(), loss_G.item()
</code></pre>
<h3 id="stylegan-concepts"><a class="header" href="#stylegan-concepts">StyleGAN Concepts</a></h3>
<pre><code class="language-python">class StyleGANGenerator(nn.Module):
    """Simplified StyleGAN architecture"""
    def __init__(self, latent_dim=512, style_dim=512, n_mlp=8):
        super(StyleGANGenerator, self).__init__()
        
        # Mapping network (converts z to w)
        layers = []
        for i in range(n_mlp):
            layers.append(nn.Linear(latent_dim if i == 0 else style_dim, style_dim))
            layers.append(nn.LeakyReLU(0.2))
        self.mapping = nn.Sequential(*layers)
        
        # Synthesis network (generates image from w)
        self.const_input = nn.Parameter(torch.randn(1, 512, 4, 4))
        
        # Progressive layers with AdaIN
        self.prog_blocks = nn.ModuleList()
        self.style_blocks = nn.ModuleList()
        
        channels = [512, 512, 512, 256, 128, 64, 32]
        for i in range(len(channels) - 1):
            self.prog_blocks.append(
                nn.Sequential(
                    nn.Upsample(scale_factor=2),
                    nn.Conv2d(channels[i], channels[i+1], 3, padding=1),
                    nn.LeakyReLU(0.2)
                )
            )
            self.style_blocks.append(
                nn.Linear(style_dim, channels[i+1] * 2)  # For AdaIN
            )
        
        self.to_rgb = nn.Conv2d(channels[-1], 3, 1)
    
    def forward(self, z):
        # Map to style space
        w = self.mapping(z)
        
        # Start with constant
        x = self.const_input.repeat(z.size(0), 1, 1, 1)
        
        # Apply progressive blocks with style modulation
        for prog_block, style_block in zip(self.prog_blocks, self.style_blocks):
            x = prog_block(x)
            
            # AdaIN (Adaptive Instance Normalization)
            style = style_block(w).unsqueeze(2).unsqueeze(3)
            style_mean, style_std = style.chunk(2, 1)
            
            x = F.instance_norm(x)
            x = x * (style_std + 1) + style_mean
        
        # Convert to RGB
        img = self.to_rgb(x)
        return torch.tanh(img)
</code></pre>
<h2 id="variational-autoencoders"><a class="header" href="#variational-autoencoders">Variational Autoencoders</a></h2>
<p>VAEs learn a latent representation by maximizing a variational lower bound on the data likelihood.</p>
<p><strong>Objective (ELBO):</strong></p>
<pre><code>log p(x) ≥ E_q[log p(x|z)] - KL(q(z|x) || p(z))
</code></pre>
<h3 id="basic-vae"><a class="header" href="#basic-vae">Basic VAE</a></h3>
<pre><code class="language-python">class VAE(nn.Module):
    def __init__(self, input_dim=784, latent_dim=20, hidden_dim=400):
        super(VAE, self).__init__()
        
        # Encoder
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc_mu = nn.Linear(hidden_dim, latent_dim)
        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)
        
        # Decoder
        self.fc3 = nn.Linear(latent_dim, hidden_dim)
        self.fc4 = nn.Linear(hidden_dim, input_dim)
    
    def encode(self, x):
        """Encode input to latent distribution parameters"""
        h = F.relu(self.fc1(x))
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar
    
    def reparameterize(self, mu, logvar):
        """Reparameterization trick"""
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        """Decode latent to output"""
        h = F.relu(self.fc3(z))
        return torch.sigmoid(self.fc4(h))
    
    def forward(self, x):
        mu, logvar = self.encode(x.view(-1, 784))
        z = self.reparameterize(mu, logvar)
        recon = self.decode(z)
        return recon, mu, logvar

def vae_loss(recon_x, x, mu, logvar):
    """VAE loss function"""
    # Reconstruction loss (binary cross-entropy)
    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')
    
    # KL divergence
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    
    return BCE + KLD

# Training
model = VAE()
optimizer = optim.Adam(model.parameters(), lr=0.001)

def train_vae(model, dataloader, num_epochs=10):
    model.train()
    for epoch in range(num_epochs):
        train_loss = 0
        for batch_idx, (data, _) in enumerate(dataloader):
            optimizer.zero_grad()
            
            recon_batch, mu, logvar = model(data)
            loss = vae_loss(recon_batch, data, mu, logvar)
            
            loss.backward()
            train_loss += loss.item()
            optimizer.step()
            
            if batch_idx % 100 == 0:
                print(f'Epoch: {epoch} [{batch_idx * len(data)}/{len(dataloader.dataset)}] '
                      f'Loss: {loss.item() / len(data):.4f}')
        
        print(f'Epoch {epoch} Average loss: {train_loss / len(dataloader.dataset):.4f}')
</code></pre>
<h3 id="convolutional-vae"><a class="header" href="#convolutional-vae">Convolutional VAE</a></h3>
<pre><code class="language-python">class ConvVAE(nn.Module):
    def __init__(self, latent_dim=128, channels=3):
        super(ConvVAE, self).__init__()
        
        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(channels, 32, 4, 2, 1),  # 32x32 -&gt; 16x16
            nn.ReLU(),
            nn.Conv2d(32, 64, 4, 2, 1),        # 16x16 -&gt; 8x8
            nn.ReLU(),
            nn.Conv2d(64, 128, 4, 2, 1),       # 8x8 -&gt; 4x4
            nn.ReLU(),
            nn.Conv2d(128, 256, 4, 2, 1),      # 4x4 -&gt; 2x2
            nn.ReLU()
        )
        
        self.fc_mu = nn.Linear(256 * 2 * 2, latent_dim)
        self.fc_logvar = nn.Linear(256 * 2 * 2, latent_dim)
        
        # Decoder
        self.fc_decode = nn.Linear(latent_dim, 256 * 2 * 2)
        
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 4, 2, 1),  # 2x2 -&gt; 4x4
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, 4, 2, 1),   # 4x4 -&gt; 8x8
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 4, 2, 1),    # 8x8 -&gt; 16x16
            nn.ReLU(),
            nn.ConvTranspose2d(32, channels, 4, 2, 1),  # 16x16 -&gt; 32x32
            nn.Sigmoid()
        )
    
    def encode(self, x):
        h = self.encoder(x)
        h = h.view(h.size(0), -1)
        return self.fc_mu(h), self.fc_logvar(h)
    
    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        h = self.fc_decode(z)
        h = h.view(h.size(0), 256, 2, 2)
        return self.decoder(h)
    
    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar
</code></pre>
<h3 id="beta-vae"><a class="header" href="#beta-vae">Beta-VAE</a></h3>
<pre><code class="language-python">def beta_vae_loss(recon_x, x, mu, logvar, beta=4.0):
    """Beta-VAE loss with adjustable KL weight"""
    # Reconstruction loss
    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')
    
    # KL divergence with beta weight
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    
    return BCE + beta * KLD
</code></pre>
<h2 id="normalizing-flows"><a class="header" href="#normalizing-flows">Normalizing Flows</a></h2>
<p>Flow models use invertible transformations to model complex distributions.</p>
<h3 id="simple-flow"><a class="header" href="#simple-flow">Simple Flow</a></h3>
<pre><code class="language-python">class CouplingLayer(nn.Module):
    """Affine coupling layer"""
    def __init__(self, dim, hidden_dim=256):
        super(CouplingLayer, self).__init__()
        self.dim = dim
        self.split = dim // 2
        
        # Scale and translate networks
        self.scale_net = nn.Sequential(
            nn.Linear(self.split, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, dim - self.split),
            nn.Tanh()
        )
        
        self.translate_net = nn.Sequential(
            nn.Linear(self.split, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, dim - self.split)
        )
    
    def forward(self, x, reverse=False):
        x1, x2 = x[:, :self.split], x[:, self.split:]
        
        if not reverse:
            # Forward pass
            s = self.scale_net(x1)
            t = self.translate_net(x1)
            y2 = x2 * torch.exp(s) + t
            y = torch.cat([x1, y2], dim=1)
            log_det = torch.sum(s, dim=1)
        else:
            # Inverse pass
            s = self.scale_net(x1)
            t = self.translate_net(x1)
            y2 = (x2 - t) * torch.exp(-s)
            y = torch.cat([x1, y2], dim=1)
            log_det = -torch.sum(s, dim=1)
        
        return y, log_det

class NormalizingFlow(nn.Module):
    def __init__(self, dim, num_layers=8):
        super(NormalizingFlow, self).__init__()
        
        self.layers = nn.ModuleList([
            CouplingLayer(dim) for _ in range(num_layers)
        ])
    
    def forward(self, x, reverse=False):
        log_det_sum = 0
        
        layers = reversed(self.layers) if reverse else self.layers
        
        for layer in layers:
            x, log_det = layer(x, reverse=reverse)
            log_det_sum += log_det
        
        return x, log_det_sum
    
    def log_prob(self, x):
        """Compute log probability"""
        z, log_det = self.forward(x, reverse=False)
        
        # Base distribution (standard normal)
        log_prob_z = -0.5 * (z ** 2 + np.log(2 * np.pi)).sum(dim=1)
        
        return log_prob_z + log_det
</code></pre>
<h2 id="autoregressive-models"><a class="header" href="#autoregressive-models">Autoregressive Models</a></h2>
<p>Generate data sequentially, one element at a time.</p>
<h3 id="pixelcnn"><a class="header" href="#pixelcnn">PixelCNN</a></h3>
<pre><code class="language-python">class MaskedConv2d(nn.Conv2d):
    """Masked convolution for autoregressive generation"""
    def __init__(self, mask_type, *args, **kwargs):
        super(MaskedConv2d, self).__init__(*args, **kwargs)
        self.register_buffer('mask', torch.zeros_like(self.weight))
        
        self.mask[:, :, :self.kernel_size[0] // 2] = 1
        self.mask[:, :, self.kernel_size[0] // 2, :self.kernel_size[1] // 2] = 1
        
        if mask_type == 'A':
            # Mask type A: exclude center pixel
            self.mask[:, :, self.kernel_size[0] // 2, self.kernel_size[1] // 2] = 0
    
    def forward(self, x):
        self.weight.data *= self.mask
        return super(MaskedConv2d, self).forward(x)

class PixelCNN(nn.Module):
    def __init__(self, n_channels=1, n_filters=64, n_layers=7):
        super(PixelCNN, self).__init__()
        
        self.layers = nn.ModuleList()
        
        # First layer (mask type A)
        self.layers.append(
            nn.Sequential(
                MaskedConv2d('A', n_channels, n_filters, 7, padding=3),
                nn.BatchNorm2d(n_filters),
                nn.ReLU()
            )
        )
        
        # Hidden layers (mask type B)
        for _ in range(n_layers):
            self.layers.append(
                nn.Sequential(
                    MaskedConv2d('B', n_filters, n_filters, 7, padding=3),
                    nn.BatchNorm2d(n_filters),
                    nn.ReLU()
                )
            )
        
        # Output layer
        self.output = nn.Conv2d(n_filters, n_channels * 256, 1)
    
    def forward(self, x):
        for layer in self.layers:
            x = layer(x)
        
        x = self.output(x)
        
        # Reshape for pixel-wise softmax
        b, _, h, w = x.size()
        x = x.view(b, 256, -1, h, w)
        
        return x
</code></pre>
<h2 id="energy-based-models"><a class="header" href="#energy-based-models">Energy-Based Models</a></h2>
<p>Model probability as energy function: p(x) ∝ exp(-E(x))</p>
<pre><code class="language-python">class EnergyBasedModel(nn.Module):
    def __init__(self, input_dim):
        super(EnergyBasedModel, self).__init__()
        
        self.energy_net = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, 1)
        )
    
    def energy(self, x):
        """Compute energy E(x)"""
        return self.energy_net(x)
    
    def sample_langevin(self, x, n_steps=100, step_size=0.01):
        """Sample using Langevin dynamics"""
        x = x.clone().detach().requires_grad_(True)
        
        for _ in range(n_steps):
            energy = self.energy(x).sum()
            grad = torch.autograd.grad(energy, x)[0]
            
            noise = torch.randn_like(x) * np.sqrt(step_size * 2)
            x = x - step_size * grad + noise
        
        return x.detach()
</code></pre>
<h2 id="diffusion-models"><a class="header" href="#diffusion-models">Diffusion Models</a></h2>
<p>Gradually add noise then learn to denoise.</p>
<h3 id="ddpm-denoising-diffusion-probabilistic-models"><a class="header" href="#ddpm-denoising-diffusion-probabilistic-models">DDPM (Denoising Diffusion Probabilistic Models)</a></h3>
<pre><code class="language-python">class DiffusionModel(nn.Module):
    def __init__(self, timesteps=1000):
        super(DiffusionModel, self).__init__()
        self.timesteps = timesteps
        
        # Linear beta schedule
        self.betas = torch.linspace(0.0001, 0.02, timesteps)
        self.alphas = 1 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)
        
        # Noise prediction network (U-Net)
        self.noise_predictor = self._build_unet()
    
    def _build_unet(self):
        """Simple U-Net for noise prediction"""
        # Simplified version
        return nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 3, 3, padding=1)
        )
    
    def q_sample(self, x0, t, noise=None):
        """Forward diffusion: add noise to x0"""
        if noise is None:
            noise = torch.randn_like(x0)
        
        sqrt_alphas_cumprod_t = self.alphas_cumprod[t].sqrt()
        sqrt_one_minus_alphas_cumprod_t = (1 - self.alphas_cumprod[t]).sqrt()
        
        return sqrt_alphas_cumprod_t * x0 + sqrt_one_minus_alphas_cumprod_t * noise
    
    def p_sample(self, xt, t):
        """Reverse diffusion: denoise xt"""
        # Predict noise
        predicted_noise = self.noise_predictor(xt)
        
        # Compute x_{t-1}
        alpha_t = self.alphas[t]
        alpha_cumprod_t = self.alphas_cumprod[t]
        beta_t = self.betas[t]
        
        x0_pred = (xt - ((1 - alpha_t) / (1 - alpha_cumprod_t).sqrt()) * predicted_noise) / alpha_t.sqrt()
        
        if t &gt; 0:
            noise = torch.randn_like(xt)
            x_prev = x0_pred * alpha_t.sqrt() + (1 - alpha_t).sqrt() * noise
        else:
            x_prev = x0_pred
        
        return x_prev
    
    def sample(self, shape):
        """Generate samples"""
        device = next(self.parameters()).device
        
        # Start from random noise
        x = torch.randn(shape).to(device)
        
        # Iteratively denoise
        for t in reversed(range(self.timesteps)):
            x = self.p_sample(x, t)
        
        return x
</code></pre>
<h2 id="evaluation-metrics"><a class="header" href="#evaluation-metrics">Evaluation Metrics</a></h2>
<pre><code class="language-python"># Inception Score (IS)
def inception_score(imgs, splits=10):
    """Higher is better"""
    from torchvision.models import inception_v3
    
    inception_model = inception_v3(pretrained=True, transform_input=False)
    inception_model.eval()
    
    # Get predictions
    with torch.no_grad():
        preds = inception_model(imgs)
        preds = F.softmax(preds, dim=1)
    
    # Compute IS
    split_scores = []
    for k in range(splits):
        part = preds[k * (len(preds) // splits): (k + 1) * (len(preds) // splits)]
        py = part.mean(dim=0)
        scores = []
        for i in range(part.shape[0]):
            pyx = part[i]
            scores.append((pyx * (torch.log(pyx) - torch.log(py))).sum())
        split_scores.append(torch.exp(torch.mean(torch.stack(scores))))
    
    return torch.mean(torch.stack(split_scores)), torch.std(torch.stack(split_scores))

# Fréchet Inception Distance (FID)
def calculate_fid(real_imgs, fake_imgs):
    """Lower is better"""
    # Extract features using Inception network
    # Calculate mean and covariance
    # Compute FID score
    pass
</code></pre>
<h2 id="practical-tips"><a class="header" href="#practical-tips">Practical Tips</a></h2>
<ol>
<li><strong>GAN Training</strong>: Balance G and D, use label smoothing, add noise to inputs</li>
<li><strong>VAE</strong>: Choose appropriate beta value, use warm-up for KL term</li>
<li><strong>Stability</strong>: Monitor losses, use spectral normalization</li>
<li><strong>Architecture</strong>: Start simple, gradually add complexity</li>
<li><strong>Evaluation</strong>: Use multiple metrics (IS, FID, visual inspection)</li>
</ol>
<h2 id="resources"><a class="header" href="#resources">Resources</a></h2>
<ul>
<li>"Generative Deep Learning" by David Foster</li>
<li>OpenAI papers: https://openai.com/research/</li>
<li>Distill.pub: https://distill.pub/</li>
<li>Papers with Code: https://paperswithcode.com/</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../machine_learning/deep_reinforcement_learning.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../machine_learning/deep_generative_models.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../machine_learning/deep_reinforcement_learning.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../machine_learning/deep_generative_models.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
