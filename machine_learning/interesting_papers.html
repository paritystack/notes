<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Interesting Papers - My Notes</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon-de23e50b.svg">
        <link rel="shortcut icon" href="../favicon-8114d1fc.png">
        <link rel="stylesheet" href="../css/variables-8adf115d.css">
        <link rel="stylesheet" href="../css/general-2459343d.css">
        <link rel="stylesheet" href="../css/chrome-ae938929.css">
        <link rel="stylesheet" href="../css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="../highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="../tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="../ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "../searchindex-c8cb17df.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc-b1a7955d.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">My Notes</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="interesting-machine-learning-papers"><a class="header" href="#interesting-machine-learning-papers">Interesting Machine Learning Papers</a></h1>
<p>Key papers that shaped the field of machine learning and deep learning.</p>
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<ol>
<li><a href="#computer-vision">Computer Vision</a></li>
<li><a href="#natural-language-processing">Natural Language Processing</a></li>
<li><a href="#generative-models">Generative Models</a></li>
<li><a href="#reinforcement-learning">Reinforcement Learning</a></li>
<li><a href="#general-machine-learning">General Machine Learning</a></li>
<li><a href="#optimization">Optimization</a></li>
</ol>
<h2 id="computer-vision"><a class="header" href="#computer-vision">Computer Vision</a></h2>
<h3 id="alexnet-2012"><a class="header" href="#alexnet-2012">AlexNet (2012)</a></h3>
<p><strong>ImageNet Classification with Deep Convolutional Neural Networks</strong></p>
<ul>
<li>Authors: Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton</li>
<li>Key Contributions:
<ul>
<li>First deep CNN to win ImageNet competition</li>
<li>Used ReLU activation, dropout, and data augmentation</li>
<li>GPU training for deep networks</li>
<li>Reduced error rate from 26% to 15.3%</li>
</ul>
</li>
<li>Impact: Sparked deep learning revolution</li>
</ul>
<h3 id="vggnet-2014"><a class="header" href="#vggnet-2014">VGGNet (2014)</a></h3>
<p><strong>Very Deep Convolutional Networks for Large-Scale Image Recognition</strong></p>
<ul>
<li>Authors: Karen Simonyan, Andrew Zisserman</li>
<li>Key Contributions:
<ul>
<li>Showed depth is crucial (16-19 layers)</li>
<li>Used small 3x3 filters throughout</li>
<li>Simple, homogeneous architecture</li>
</ul>
</li>
<li>Architecture: Stacked 3x3 conv layers, 2x2 max pooling</li>
</ul>
<h3 id="resnet-2015"><a class="header" href="#resnet-2015">ResNet (2015)</a></h3>
<p><strong>Deep Residual Learning for Image Recognition</strong></p>
<ul>
<li>Authors: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</li>
<li>Key Contributions:
<ul>
<li>Residual connections solve vanishing gradient problem</li>
<li>Enabled training of networks with 100+ layers</li>
<li>Won ImageNet 2015 with 152 layers</li>
<li>Skip connections: y = F(x) + x</li>
</ul>
</li>
<li>Impact: Fundamental building block for modern architectures</li>
</ul>
<h3 id="vision-transformer-vit-2020"><a class="header" href="#vision-transformer-vit-2020">Vision Transformer (ViT) (2020)</a></h3>
<p><strong>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</strong></p>
<ul>
<li>Authors: Alexey Dosovitskiy et al. (Google Research)</li>
<li>Key Contributions:
<ul>
<li>Applied transformers directly to image patches</li>
<li>Competitive with CNNs on large datasets</li>
<li>Self-attention for vision tasks</li>
</ul>
</li>
<li>Architecture:
<ul>
<li>Split image into patches</li>
<li>Linear embedding of patches</li>
<li>Add position embeddings</li>
<li>Standard transformer encoder</li>
</ul>
</li>
</ul>
<h3 id="yolo-2015"><a class="header" href="#yolo-2015">YOLO (2015)</a></h3>
<p><strong>You Only Look Once: Unified, Real-Time Object Detection</strong></p>
<ul>
<li>Authors: Joseph Redmon et al.</li>
<li>Key Contributions:
<ul>
<li>Single-stage object detection</li>
<li>Real-time performance (45 FPS)</li>
<li>End-to-end training</li>
<li>Grid-based prediction</li>
</ul>
</li>
</ul>
<h3 id="mask-r-cnn-2017"><a class="header" href="#mask-r-cnn-2017">Mask R-CNN (2017)</a></h3>
<p><strong>Mask R-CNN</strong></p>
<ul>
<li>Authors: Kaiming He, Georgia Gkioxari, Piotr Dollár, Ross Girshick</li>
<li>Key Contributions:
<ul>
<li>Instance segmentation framework</li>
<li>Extends Faster R-CNN with mask branch</li>
<li>Parallel prediction of masks and classes</li>
</ul>
</li>
</ul>
<h2 id="natural-language-processing"><a class="header" href="#natural-language-processing">Natural Language Processing</a></h2>
<h3 id="word2vec-2013"><a class="header" href="#word2vec-2013">Word2Vec (2013)</a></h3>
<p><strong>Efficient Estimation of Word Representations in Vector Space</strong></p>
<ul>
<li>Authors: Tomas Mikolov et al. (Google)</li>
<li>Key Contributions:
<ul>
<li>Distributed word representations</li>
<li>Skip-gram and CBOW architectures</li>
<li>Captures semantic relationships</li>
<li>king - man + woman ≈ queen</li>
</ul>
</li>
<li>Impact: Foundation for modern NLP embeddings</li>
</ul>
<h3 id="attention-is-all-you-need-2017"><a class="header" href="#attention-is-all-you-need-2017">Attention Is All You Need (2017)</a></h3>
<p><strong>Attention Is All You Need</strong></p>
<ul>
<li>Authors: Ashish Vaswani et al. (Google Brain)</li>
<li>Key Contributions:
<ul>
<li>Introduced Transformer architecture</li>
<li>Self-attention mechanism</li>
<li>No recurrence or convolution</li>
<li>Parallel training</li>
</ul>
</li>
<li>Architecture:
<ul>
<li>Multi-head self-attention</li>
<li>Position-wise feed-forward networks</li>
<li>Positional encoding</li>
<li>Encoder-decoder structure</li>
</ul>
</li>
<li>Impact: Revolutionized NLP and beyond</li>
</ul>
<h3 id="bert-2018"><a class="header" href="#bert-2018">BERT (2018)</a></h3>
<p><strong>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</strong></p>
<ul>
<li>Authors: Jacob Devlin et al. (Google AI)</li>
<li>Key Contributions:
<ul>
<li>Bidirectional pre-training</li>
<li>Masked Language Modeling (MLM)</li>
<li>Next Sentence Prediction (NSP)</li>
<li>Transfer learning for NLP</li>
</ul>
</li>
<li>Pre-training objectives:
<ul>
<li>Mask 15% of tokens, predict them</li>
<li>Predict if sentence B follows A</li>
</ul>
</li>
<li>Impact: Set new SOTA on 11 NLP tasks</li>
</ul>
<h3 id="gpt-2018-2023"><a class="header" href="#gpt-2018-2023">GPT (2018-2023)</a></h3>
<p><strong>Improving Language Understanding by Generative Pre-Training</strong></p>
<ul>
<li>GPT-1 (2018): 117M parameters, unsupervised pre-training</li>
<li>GPT-2 (2019): 1.5B parameters, zero-shot learning</li>
<li>GPT-3 (2020): 175B parameters, few-shot learning</li>
<li>GPT-4 (2023): Multimodal, improved reasoning</li>
</ul>
<p>Key Contributions:</p>
<ul>
<li>Autoregressive language modeling</li>
<li>Scaling laws for language models</li>
<li>In-context learning</li>
<li>Emergent capabilities at scale</li>
</ul>
<h3 id="t5-2019"><a class="header" href="#t5-2019">T5 (2019)</a></h3>
<p><strong>Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</strong></p>
<ul>
<li>Authors: Colin Raffel et al. (Google)</li>
<li>Key Contributions:
<ul>
<li>Unified text-to-text framework</li>
<li>All NLP tasks as text generation</li>
<li>Comprehensive study of transfer learning</li>
</ul>
</li>
<li>Format: “translate English to German: text” → “translation”</li>
</ul>
<h3 id="electra-2020"><a class="header" href="#electra-2020">ELECTRA (2020)</a></h3>
<p><strong>ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators</strong></p>
<ul>
<li>Authors: Kevin Clark et al. (Stanford/Google)</li>
<li>Key Contributions:
<ul>
<li>Replaced token detection (RTD)</li>
<li>More sample-efficient than BERT</li>
<li>Generator-discriminator framework</li>
<li>Discriminator predicts which tokens are replaced</li>
</ul>
</li>
</ul>
<h2 id="generative-models"><a class="header" href="#generative-models">Generative Models</a></h2>
<h3 id="gan-2014"><a class="header" href="#gan-2014">GAN (2014)</a></h3>
<p><strong>Generative Adversarial Networks</strong></p>
<ul>
<li>Authors: Ian Goodfellow et al.</li>
<li>Key Contributions:
<ul>
<li>Two-player minimax game</li>
<li>Generator vs Discriminator</li>
<li>Implicit density modeling</li>
</ul>
</li>
<li>Objective: min_G max_D V(D,G) = E[log D(x)] + E[log(1-D(G(z)))]</li>
<li>Impact: New paradigm for generative modeling</li>
</ul>
<h3 id="dcgan-2015"><a class="header" href="#dcgan-2015">DCGAN (2015)</a></h3>
<p><strong>Unsupervised Representation Learning with Deep Convolutional GANs</strong></p>
<ul>
<li>Authors: Alec Radford, Luke Metz, Soumith Chintala</li>
<li>Key Contributions:
<ul>
<li>Architectural guidelines for stable GAN training</li>
<li>All convolutional network</li>
<li>Batch normalization</li>
<li>No fully connected layers</li>
</ul>
</li>
<li>Best practices: Strided convolutions, BatchNorm, LeakyReLU</li>
</ul>
<h3 id="stylegan-2018-2020"><a class="header" href="#stylegan-2018-2020">StyleGAN (2018-2020)</a></h3>
<p><strong>A Style-Based Generator Architecture for GANs</strong></p>
<ul>
<li>Authors: Tero Karras et al. (NVIDIA)</li>
<li>Key Contributions:
<ul>
<li>Style-based generator</li>
<li>Adaptive Instance Normalization (AdaIN)</li>
<li>Progressive growing</li>
<li>High-quality face generation</li>
</ul>
</li>
<li>StyleGAN2 improvements: Weight demodulation, path length regularization</li>
</ul>
<h3 id="vae-2013"><a class="header" href="#vae-2013">VAE (2013)</a></h3>
<p><strong>Auto-Encoding Variational Bayes</strong></p>
<ul>
<li>Authors: Diederik Kingma, Max Welling</li>
<li>Key Contributions:
<ul>
<li>Variational inference for latent variable models</li>
<li>Reparameterization trick</li>
<li>ELBO objective</li>
<li>Probabilistic encoder-decoder</li>
</ul>
</li>
<li>Objective: Maximize ELBO = E[log p(x|z)] - KL(q(z|x)||p(z))</li>
</ul>
<h3 id="diffusion-models-2020"><a class="header" href="#diffusion-models-2020">Diffusion Models (2020)</a></h3>
<p><strong>Denoising Diffusion Probabilistic Models</strong></p>
<ul>
<li>Authors: Jonathan Ho, Ajay Jain, Pieter Abbeel</li>
<li>Key Contributions:
<ul>
<li>Iterative denoising process</li>
<li>High-quality image generation</li>
<li>Stable training</li>
</ul>
</li>
<li>Process:
<ul>
<li>Forward: Gradually add noise</li>
<li>Reverse: Learn to denoise</li>
</ul>
</li>
</ul>
<h3 id="dall-e-2-2022"><a class="header" href="#dall-e-2-2022">DALL-E 2 (2022)</a></h3>
<p><strong>Hierarchical Text-Conditional Image Generation with CLIP Latents</strong></p>
<ul>
<li>Authors: Aditya Ramesh et al. (OpenAI)</li>
<li>Key Contributions:
<ul>
<li>Text-to-image generation</li>
<li>CLIP guidance</li>
<li>Prior and decoder models</li>
<li>Improved image quality and text alignment</li>
</ul>
</li>
</ul>
<h3 id="stable-diffusion-2022"><a class="header" href="#stable-diffusion-2022">Stable Diffusion (2022)</a></h3>
<p><strong>High-Resolution Image Synthesis with Latent Diffusion Models</strong></p>
<ul>
<li>Authors: Robin Rombach et al.</li>
<li>Key Contributions:
<ul>
<li>Diffusion in latent space</li>
<li>More efficient than pixel-space diffusion</li>
<li>Text-conditional generation</li>
<li>Open source</li>
</ul>
</li>
</ul>
<h2 id="reinforcement-learning"><a class="header" href="#reinforcement-learning">Reinforcement Learning</a></h2>
<h3 id="dqn-2013"><a class="header" href="#dqn-2013">DQN (2013)</a></h3>
<p><strong>Playing Atari with Deep Reinforcement Learning</strong></p>
<ul>
<li>Authors: Volodymyr Mnih et al. (DeepMind)</li>
<li>Key Contributions:
<ul>
<li>Deep Q-learning</li>
<li>Experience replay</li>
<li>Target network</li>
<li>End-to-end RL from pixels</li>
</ul>
</li>
<li>Impact: First deep RL to master Atari games</li>
</ul>
<h3 id="alphago-2016"><a class="header" href="#alphago-2016">AlphaGo (2016)</a></h3>
<p><strong>Mastering the game of Go with deep neural networks and tree search</strong></p>
<ul>
<li>Authors: David Silver et al. (DeepMind)</li>
<li>Key Contributions:
<ul>
<li>Combined deep learning with Monte Carlo Tree Search</li>
<li>Policy and value networks</li>
<li>Self-play training</li>
<li>Beat world champion Lee Sedol</li>
</ul>
</li>
<li>AlphaZero (2017): Generalized to chess and shogi</li>
</ul>
<h3 id="ppo-2017"><a class="header" href="#ppo-2017">PPO (2017)</a></h3>
<p><strong>Proximal Policy Optimization Algorithms</strong></p>
<ul>
<li>Authors: John Schulman et al. (OpenAI)</li>
<li>Key Contributions:
<ul>
<li>Clipped surrogate objective</li>
<li>Stable policy updates</li>
<li>Sample efficient</li>
<li>Easy to implement</li>
</ul>
</li>
<li>Widely used in practice</li>
</ul>
<h3 id="muzero-2019"><a class="header" href="#muzero-2019">MuZero (2019)</a></h3>
<p><strong>Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model</strong></p>
<ul>
<li>Authors: Julian Schrittwieser et al. (DeepMind)</li>
<li>Key Contributions:
<ul>
<li>Model-based RL without knowing rules</li>
<li>Learns dynamics model</li>
<li>Plans in latent space</li>
<li>Superhuman performance</li>
</ul>
</li>
</ul>
<h3 id="decision-transformer-2021"><a class="header" href="#decision-transformer-2021">Decision Transformer (2021)</a></h3>
<p><strong>Decision Transformer: Reinforcement Learning via Sequence Modeling</strong></p>
<ul>
<li>Authors: Lili Chen et al. (Berkeley)</li>
<li>Key Contributions:
<ul>
<li>RL as sequence modeling</li>
<li>Conditional generation of actions</li>
<li>Leverages transformer architecture</li>
<li>Offline RL</li>
</ul>
</li>
</ul>
<h2 id="general-machine-learning"><a class="header" href="#general-machine-learning">General Machine Learning</a></h2>
<h3 id="dropout-2014"><a class="header" href="#dropout-2014">Dropout (2014)</a></h3>
<p><strong>Dropout: A Simple Way to Prevent Neural Networks from Overfitting</strong></p>
<ul>
<li>Authors: Nitish Srivastava et al.</li>
<li>Key Contributions:
<ul>
<li>Randomly drop units during training</li>
<li>Reduces overfitting</li>
<li>Ensemble effect</li>
<li>Simple and effective regularization</li>
</ul>
</li>
</ul>
<h3 id="batch-normalization-2015"><a class="header" href="#batch-normalization-2015">Batch Normalization (2015)</a></h3>
<p><strong>Batch Normalization: Accelerating Deep Network Training</strong></p>
<ul>
<li>Authors: Sergey Ioffe, Christian Szegedy (Google)</li>
<li>Key Contributions:
<ul>
<li>Normalize layer inputs</li>
<li>Reduces internal covariate shift</li>
<li>Enables higher learning rates</li>
<li>Acts as regularizer</li>
</ul>
</li>
<li>Operation: Normalize, then scale and shift</li>
</ul>
<h3 id="adam-optimizer-2014"><a class="header" href="#adam-optimizer-2014">Adam Optimizer (2014)</a></h3>
<p><strong>Adam: A Method for Stochastic Optimization</strong></p>
<ul>
<li>Authors: Diederik Kingma, Jimmy Ba</li>
<li>Key Contributions:
<ul>
<li>Adaptive learning rates</li>
<li>Combines momentum and RMSprop</li>
<li>Bias correction</li>
<li>Default optimizer for many tasks</li>
</ul>
</li>
</ul>
<h3 id="layer-normalization-2016"><a class="header" href="#layer-normalization-2016">Layer Normalization (2016)</a></h3>
<p><strong>Layer Normalization</strong></p>
<ul>
<li>Authors: Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey Hinton</li>
<li>Key Contributions:
<ul>
<li>Normalize across features</li>
<li>Better for RNNs and Transformers</li>
<li>No batch dependence</li>
</ul>
</li>
</ul>
<h3 id="elu-2015"><a class="header" href="#elu-2015">ELU (2015)</a></h3>
<p><strong>Fast and Accurate Deep Network Learning by Exponential Linear Units</strong></p>
<ul>
<li>Authors: Djork-Arné Clevert et al.</li>
<li>Key Contributions:
<ul>
<li>Negative values push mean towards zero</li>
<li>Reduces bias shift</li>
<li>Faster learning</li>
</ul>
</li>
</ul>
<h2 id="optimization"><a class="header" href="#optimization">Optimization</a></h2>
<h3 id="sgd-with-momentum-1999"><a class="header" href="#sgd-with-momentum-1999">SGD with Momentum (1999)</a></h3>
<p><strong>On the momentum term in gradient descent learning algorithms</strong></p>
<ul>
<li>Key Contributions:
<ul>
<li>Accumulate gradients</li>
<li>Faster convergence</li>
<li>Reduces oscillations</li>
</ul>
</li>
</ul>
<h3 id="rmsprop-2012"><a class="header" href="#rmsprop-2012">RMSprop (2012)</a></h3>
<p><strong>Neural Networks for Machine Learning - Lecture 6</strong></p>
<ul>
<li>Author: Geoffrey Hinton</li>
<li>Key Contributions:
<ul>
<li>Adaptive learning rates per parameter</li>
<li>Divides by running average of gradient magnitudes</li>
</ul>
</li>
</ul>
<h3 id="learning-rate-schedules"><a class="header" href="#learning-rate-schedules">Learning Rate Schedules</a></h3>
<p><strong>Cosine Annealing (2016)</strong></p>
<ul>
<li>SGDR: Stochastic Gradient Descent with Warm Restarts</li>
<li>Cosine decay with restarts</li>
<li>Enables finding multiple local minima</li>
</ul>
<p><strong>One Cycle Policy (2018)</strong></p>
<ul>
<li>Super-Convergence: Very Fast Training of Neural Networks</li>
<li>Cyclical learning rate with momentum</li>
<li>Train faster with fewer epochs</li>
</ul>
<h2 id="interpretability-and-explainability"><a class="header" href="#interpretability-and-explainability">Interpretability and Explainability</a></h2>
<h3 id="grad-cam-2016"><a class="header" href="#grad-cam-2016">Grad-CAM (2016)</a></h3>
<p><strong>Grad-CAM: Visual Explanations from Deep Networks</strong></p>
<ul>
<li>Authors: Ramprasaath Selvaraju et al.</li>
<li>Key Contributions:
<ul>
<li>Visualize what CNN looks at</li>
<li>Gradient-weighted class activation mapping</li>
<li>Works with any CNN architecture</li>
</ul>
</li>
</ul>
<h3 id="lime-2016"><a class="header" href="#lime-2016">LIME (2016)</a></h3>
<p><strong>“Why Should I Trust You?”: Explaining Predictions of Any Classifier</strong></p>
<ul>
<li>Authors: Marco Tulio Ribeiro et al.</li>
<li>Key Contributions:
<ul>
<li>Local interpretable model-agnostic explanations</li>
<li>Approximate complex models locally</li>
<li>Works with any classifier</li>
</ul>
</li>
</ul>
<h3 id="shap-2017"><a class="header" href="#shap-2017">SHAP (2017)</a></h3>
<p><strong>A Unified Approach to Interpreting Model Predictions</strong></p>
<ul>
<li>Authors: Scott Lundberg, Su-In Lee</li>
<li>Key Contributions:
<ul>
<li>Shapley values for feature importance</li>
<li>Game-theoretic approach</li>
<li>Consistent and locally accurate</li>
</ul>
</li>
</ul>
<h2 id="efficiency-and-compression"><a class="header" href="#efficiency-and-compression">Efficiency and Compression</a></h2>
<h3 id="mobilenets-2017"><a class="header" href="#mobilenets-2017">MobileNets (2017)</a></h3>
<p><strong>MobileNets: Efficient Convolutional Neural Networks for Mobile Vision</strong></p>
<ul>
<li>Authors: Andrew Howard et al. (Google)</li>
<li>Key Contributions:
<ul>
<li>Depthwise separable convolutions</li>
<li>Width and resolution multipliers</li>
<li>Efficient for mobile devices</li>
</ul>
</li>
</ul>
<h3 id="squeezenet-2016"><a class="header" href="#squeezenet-2016">SqueezeNet (2016)</a></h3>
<p><strong>SqueezeNet: AlexNet-level accuracy with 50x fewer parameters</strong></p>
<ul>
<li>Authors: Forrest Iandola et al.</li>
<li>Key Contributions:
<ul>
<li>Fire modules (squeeze and expand)</li>
<li>50x fewer parameters than AlexNet</li>
<li>Small model size</li>
</ul>
</li>
</ul>
<h3 id="knowledge-distillation-2015"><a class="header" href="#knowledge-distillation-2015">Knowledge Distillation (2015)</a></h3>
<p><strong>Distilling the Knowledge in a Neural Network</strong></p>
<ul>
<li>Authors: Geoffrey Hinton, Oriol Vinyals, Jeff Dean</li>
<li>Key Contributions:
<ul>
<li>Transfer knowledge from large to small model</li>
<li>Soft targets from teacher</li>
<li>Temperature scaling</li>
</ul>
</li>
</ul>
<h3 id="pruning-2015"><a class="header" href="#pruning-2015">Pruning (2015)</a></h3>
<p><strong>Learning both Weights and Connections for Efficient Neural Networks</strong></p>
<ul>
<li>Authors: Song Han et al.</li>
<li>Key Contributions:
<ul>
<li>Remove unimportant weights</li>
<li>Magnitude-based pruning</li>
<li>Reduce model size and computation</li>
</ul>
</li>
</ul>
<h2 id="meta-learning"><a class="header" href="#meta-learning">Meta-Learning</a></h2>
<h3 id="maml-2017"><a class="header" href="#maml-2017">MAML (2017)</a></h3>
<p><strong>Model-Agnostic Meta-Learning for Fast Adaptation</strong></p>
<ul>
<li>Authors: Chelsea Finn, Pieter Abbeel, Sergey Levine</li>
<li>Key Contributions:
<ul>
<li>Learn good initialization</li>
<li>Fast adaptation to new tasks</li>
<li>Few-shot learning</li>
<li>Bi-level optimization</li>
</ul>
</li>
</ul>
<h3 id="prototypical-networks-2017"><a class="header" href="#prototypical-networks-2017">Prototypical Networks (2017)</a></h3>
<p><strong>Prototypical Networks for Few-shot Learning</strong></p>
<ul>
<li>Authors: Jake Snell, Kevin Swersky, Richard Zemel</li>
<li>Key Contributions:
<ul>
<li>Learn metric space</li>
<li>Class prototypes as centroids</li>
<li>Simple and effective</li>
</ul>
</li>
</ul>
<h2 id="self-supervised-learning"><a class="header" href="#self-supervised-learning">Self-Supervised Learning</a></h2>
<h3 id="simclr-2020"><a class="header" href="#simclr-2020">SimCLR (2020)</a></h3>
<p><strong>A Simple Framework for Contrastive Learning of Visual Representations</strong></p>
<ul>
<li>Authors: Ting Chen et al. (Google)</li>
<li>Key Contributions:
<ul>
<li>Contrastive learning framework</li>
<li>Large batch sizes crucial</li>
<li>Strong data augmentation</li>
<li>No labels needed</li>
</ul>
</li>
</ul>
<h3 id="byol-2020"><a class="header" href="#byol-2020">BYOL (2020)</a></h3>
<p><strong>Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning</strong></p>
<ul>
<li>Authors: Jean-Bastien Grill et al. (DeepMind)</li>
<li>Key Contributions:
<ul>
<li>No negative pairs needed</li>
<li>Online and target networks</li>
<li>Momentum encoder</li>
<li>State-of-the-art representations</li>
</ul>
</li>
</ul>
<h3 id="mae-2021"><a class="header" href="#mae-2021">MAE (2021)</a></h3>
<p><strong>Masked Autoencoders Are Scalable Vision Learners</strong></p>
<ul>
<li>Authors: Kaiming He et al. (Facebook AI)</li>
<li>Key Contributions:
<ul>
<li>Mask random patches</li>
<li>Reconstruct missing pixels</li>
<li>Simple and scalable</li>
<li>Asymmetric encoder-decoder</li>
</ul>
</li>
</ul>
<h2 id="papers-to-read"><a class="header" href="#papers-to-read">Papers to Read</a></h2>
<h3 id="foundational"><a class="header" href="#foundational">Foundational</a></h3>
<ol>
<li>Neural Networks and Deep Learning (Nielsen)</li>
<li>Deep Learning Book (Goodfellow et al.)</li>
<li>Pattern Recognition and Machine Learning (Bishop)</li>
</ol>
<h3 id="recent-surveys"><a class="header" href="#recent-surveys">Recent Surveys</a></h3>
<ul>
<li>Attention mechanisms survey</li>
<li>Transfer learning survey</li>
<li>Self-supervised learning survey</li>
<li>Efficient deep learning survey</li>
</ul>
<h3 id="follow-these-venues"><a class="header" href="#follow-these-venues">Follow These Venues</a></h3>
<ul>
<li>NeurIPS, ICML, ICLR (ML conferences)</li>
<li>CVPR, ICCV, ECCV (Computer Vision)</li>
<li>ACL, EMNLP, NAACL (NLP)</li>
<li>AAAI, IJCAI (AI)</li>
</ul>
<h2 id="resources"><a class="header" href="#resources">Resources</a></h2>
<ul>
<li>arXiv.org: Pre-prints of latest research</li>
<li>Papers with Code: Papers with implementations</li>
<li>Google Scholar: Citation tracking</li>
<li>Semantic Scholar: AI-powered search</li>
<li>Distill.pub: Clear explanations</li>
<li>Two Minute Papers: Video summaries</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../machine_learning/quantization.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                            </a>

                            <a rel="next prefetch" href="../machine_learning/lora.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../machine_learning/quantization.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                    </a>

                    <a rel="next prefetch" href="../machine_learning/lora.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                    </a>
            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr-ef4e11c1.min.js"></script>
        <script src="../mark-09e88c2c.min.js"></script>
        <script src="../searcher-c2a407aa.js"></script>

        <script src="../clipboard-1626706a.min.js"></script>
        <script src="../highlight-abc7f01d.js"></script>
        <script src="../book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
